\subsection{Functions}\label{design:components}

The following sets are subsequently used to introduce the functions $\sigma$, $\phi$, $\pi$, $\rho$ and $\nu$.

\begin{enumerate}
    \item $\mathcal{Q}$ – The set of all possible natural language queries.
    \item $\mathcal{S}$ – The set of all possible database schemas.
    \item $\mathcal{E}$ – The set of all possible execution functions for SQL validation.
    \item $\mathcal{V}$ – The set of all possible embedding spaces.
    \item $\mathcal{D}$ – The set of all possible distance indices over historically observed databases.
    \item $\mathcal{C}$ – The set of all possible candidate sets $\mathcal{C}'$.
    \item $\mathcal{Q}_{\mathcal{S}}$ – The set of all valid queries over the database schema $S$.
\end{enumerate}

\subsubsection{Example Selection – $\sigma$}\label{design:selection-function}

The selection function $\sigma$ retrieves the most relevant examples from the
historical embedding space $v$ based on semantic similarity to the
input query. This function implements the core example selection mechanism 
that subsequently enables few-shot learning for SQL generation.

$$
\sigma: \mathcal{Q} \times \Omega_{\mathcal{S}} \times \mathcal{S} \times \mathcal{V} \times \mathcal{D} \rightarrow \mathcal{C}'
$$

\vspace{0.5em}

For a specific input instance, we write:

$$
\sigma(q, z, s, v, d) = \{(q_1, s_1, \omega_1, d_1), \ldots, (q_k, s_k, \omega_k, d_k)\}
$$

\vspace{0.5em}

where $q \in \mathcal{Q}$ is the input natural language query, $z \in \Omega_{\mathcal{S}}$
is the zero-shot inference result, $s \in \mathcal{S}$ is the database schema,
$v \in \mathcal{V}$ is the embedding space, $d \in \mathcal{D}$ is the distance index,
and the result is a candidate set $\mathcal{C}' \in \mathcal{C}$ containing $k$
tuples of natural language queries, schemas, corresponding SQL queries and their
combined distance.

The function utilizes cosine similarity in the embedding space to identify examples
that are semantically closest to the input query $q$, considering both masked natural
language representations and schema distance as described in Section~\ref{design:embedding}.
This approach ensures that examples are weighted by the following properties:

\begin{enumerate}
    \item \textbf{Question similarity} – Semantic similarity between the masked input
        query and historically observed natural language queries in the embedding space
        $v$, measured using cosine distance between their respective embeddings.
    \item \textbf{SQL similarity} – Structural similarity between the zero-shot inference
        result $z$ and candidate SQL queries using masked SQL representations, enabling
        pattern recognition across different database domains.
    \item \textbf{Database similarity} – Schema compatibility measured through the distance
        index $d$, ensuring selected examples operate on analogous database
        structures with similar table relationships and column types.
\end{enumerate}

The exact weighting of these can be adjusted through three constants, $w_q$, $w_s$, and $w_d$.

\begin{algorithm}
\caption{$\sigma$ - Example Selection}\label{algorithms:sigma}
\begin{algorithmic}[1]
%\Require $q \in \mathcal{Q}$, $z \in \Omega_{\mathcal{S}}$, $s \in \mathcal{S}$, $v \in \mathcal{V}$, $d \in \mathcal{D}$
%\Require $k \in \mathbb{N}$, $k \geq 1$             \Comment{Number of examples to select}
%\State $q' \gets mask(q)$                           \Comment{Mask input query}
%\State $z' \gets mask(z)$                           \Comment{Mask zero-shot result}
%\State $candidates \gets \emptyset$                 \Comment{Initialize candidate set}
%\For{each $(q_i, s_i, \omega_i) \in v$}            \Comment{Iterate through embedding space}
    %\State $sim_q \gets cosine(\iota(q'), \iota(mask(q_i)))$  \Comment{Query similarity}
    %\State $sim_s \gets cosine(\iota(z'), \iota(mask(\omega_i)))$  \Comment{SQL similarity}
    %\State $sim_d \gets d(s, s_i)$                  \Comment{Schema distance}
    %\State $score \gets w_q \cdot sim_q + w_s \cdot sim_s + w_d \cdot sim_d$
    %\State $candidates \gets candidates \cup \{(q_i, s_i, \omega_i, score)\}$
%\EndFor
%\State \Return $top\_k(candidates, k)$              \Comment{Return k highest scoring examples}
\end{algorithmic}
\end{algorithm}

\subsubsection{Schema Subsetting – $\phi$}\label{design:subsetting-function}

The subsetting function $\phi$ reduces the database schema to only include
tables, columns, and relationships that are relevant to the current set of candidates
$C$. This schema pruning mechanism reduces the complexity of the SQL generation task
and token efficiency by focusing on the most relevant schema elements.

$$
\phi: \mathcal{C}' \times \mathcal{S} \rightarrow \mathcal{S}'
$$

\vspace{0.5em}

For a specific input instance, we write:

$$
\phi(c, s) = s'
$$

\vspace{0.5em}

where $c \in \mathcal{C}'$ is a candidate set containing selected examples, $s \in \mathcal{S}$
is the full database schema, and $s' \subseteq s$ is the reduced schema subset containing
only relevant tables and columns.

The function analyzes the selected examples in $c$ to identify which schema elements
(tables, columns, foreign key relationships) are commonly referenced in similar queries.
This analysis enables the system to steer the model's attention on the most relevant
portions of potentially large and complex database schemas, thereby improving both accuracy
and computational efficiency and prevents exceeding limited context windows.

\begin{algorithm}
\caption{$\phi$ - Schema Subsetting}\label{algorithms:phi}
\begin{algorithmic}[1]
%\Require $c \in \mathcal{C}'$, $s \in \mathcal{S}$
%\State $tables \gets \emptyset$, $columns \gets \emptyset$, $relations \gets \emptyset$
%\For{each $(q_i, s_i, \omega_i, d_i) \in c$}       \Comment{Analyze selected examples}
    %\State $parsed \gets parse\_sql(\omega_i)$      \Comment{Extract schema elements from SQL}
    %\State $tables \gets tables \cup tables(parsed)$
    %\State $columns \gets columns \cup columns(parsed)$
    %\State $relations \gets relations \cup foreign\_keys(parsed)$
%\EndFor
%\State $s' \gets construct\_schema(tables, columns, relations)$  \Comment{Build reduced schema}
%\State \Return $s'$                                 \Comment{Return schema subset}
\end{algorithmic}
\end{algorithm}

\subsubsection{Query Projection – $\pi$}\label{design:projection-function}

The projection function $\pi$ represents the core translation mechanism that converts
natural language queries into SQL statements using the selected examples and database
schema. This function encapsulates the inference using LLMs that generates
candidate SQL queries based on the provided context.

$$
\pi: \mathcal{Q} \times \mathcal{S} \times \mathcal{C}' \rightarrow \Omega_{\mathcal{S}}
$$

\vspace{0.5em}

For a specific input instance, we write:

$$
\pi(q, s, c) = \omega
$$

\vspace{0.5em}

where $q \in \mathcal{Q}$ is the input natural language query, $s \in \mathcal{S}$ is
the database schema, $c \in \mathcal{C}'$ is the set of selected examples,
and $\omega \in \Omega_{\mathcal{S}}$ is the generated SQL query.

The function operates by constructing a prompt that combines the natural language
query, the relevant schema information, and the selected examples in a format
optimized for large language model inference. The model then generates a SQL query
that attempts to capture the semantic intent of the natural language input while
adhering to the constraints imposed by the database schema.

\begin{algorithm}
\caption{$\pi$ - Query Projection}\label{algorithms:pi}
\begin{algorithmic}[1]
\end{algorithmic}
\end{algorithm}

\subsubsection{Self Refinement – $\rho$}\label{design:refinement-function}

The refinement function $\rho$ implements a self-correction mechanism that iteratively
improves generated SQL queries by identifying and correcting syntax errors,
semantic inconsistencies, and execution failures. This function enables the system
to learn from its mistakes and produce higher-quality outputs through automated
feedback loops.

$$
\rho: \mathcal{Q} \times \mathcal{S} \times \mathcal{E} \times \Omega_{\mathcal{S}} \rightarrow \Omega_{\mathcal{S}}
$$

\vspace{0.5em}

For a specific input instance, we write:

$$
\rho(q, s, e, \omega_{raw}) = \omega_{refined}
$$

\vspace{0.5em}

where $q \in \mathcal{Q}$ is the original natural language query, $s \in \mathcal{S}$
is the database schema, $e \in \mathcal{E}$ is the execution function for
validation, $\omega_{raw} \in \Omega_{\mathcal{S}}$ is the previously generated SQL
query and $\omega_{refined} \in \Omega_{\mathcal{S}}$ is the improved SQL query.

The function operates by executing the candidate query against the database, analyzing
any errors or unexpected results, and then prompting the language model to generate
an improved version based on the identified issues. This iterative refinement
process continues until a valid, executable query is produced or a maximum number
of refinement attempts is reached.

\begin{algorithm}
\caption{$\rho$ - Self Refinement}\label{algorithms:rho}
\begin{algorithmic}[1]
%\Require $q \in \mathcal{Q}$, $s \in \mathcal{S}$, $e \in \mathcal{E}$, $\omega_{raw} \in \Omega_{\mathcal{S}}$
%\Require $max\_attempts \in \mathbb{N}$             \Comment{Maximum refinement attempts}
%\State $\omega_{current} \gets \omega_{raw}$
%\State $attempts \gets 0$
%\While{$attempts < max\_attempts$}
    %\If{$e(\omega_{current}, s)$}                   \Comment{Check if query is valid}
        %\State \Return $\omega_{current}$           \Comment{Return if valid}
    %\EndIf
    %\State $error \gets get\_error(e, \omega_{current}, s)$  \Comment{Extract error details}
    %\State $prompt \gets construct\_refinement\_prompt(q, s, \omega_{current}, error)$
    %\State $\omega_{current} \gets \pi(prompt, s, \emptyset)$  \Comment{Generate refined query}
    %\State $attempts \gets attempts + 1$
%\EndWhile
%\State \Return $\omega_{current}$                   \Comment{Return best attempt}
\end{algorithmic}
\end{algorithm}

\subsubsection{Voting – $\nu$}\label{design:voting-function}

The voting function $\nu$ implements a consensus mechanism that selects the most
reliable SQL query from multiple candidate solutions generated through the pipeline.
This function enhances robustness by leveraging the result distribution of multiple
generation attempts to identify the most likely correct answer.

$$
\nu: \mathcal{C} \times \mathcal{E} \rightarrow \Omega_{\mathcal{S}}
$$

\vspace{0.5em}

For a specific input instance, we write:

$$
\nu(C, e) = \omega_{consensus}
$$

where $C \in \mathcal{C}$ is a set of candidate SQL queries, $e \in \mathcal{E}$ is
the execution function for validation, and $\omega_{consensus} \in \Omega_{\mathcal{S}}$
is the selected consensus query.

\vspace{0.5em}

The voting function $\nu$ implements a majority voting algorithm similar to that
described by OmniSQL \citep{OmniSQL}, where the result that appears most frequently
across multiple generation attempts is deemed to be the most likely correct answer.
The function applies frequency-based selection among the valid candidates. In cases where
no clear majority exists, the function may apply additional heuristics such as query
complexity or execution performance to determine the final proposed query candidate $\omega_{consensus}$.

\begin{algorithm}
\caption{$\nu$ - Consensus Voting}\label{algorithms:nu}
\begin{algorithmic}[1]
%\Require $C \in \mathcal{C}$, $e \in \mathcal{E}$
%\State $valid\_queries \gets \{\omega \in C : e(\omega, s)\}$  \Comment{Filter valid queries}
%\If{$|valid\_queries| = 0$}
    %\State \Return $null$                           \Comment{No valid candidates}
%\EndIf
%\State $frequency\_map \gets \{\}$                  \Comment{Count query frequencies}
%\For{each $\omega \in valid\_queries$}
    %\State $result \gets execute(\omega, s)$        \Comment{Execute query to get result}
    %\State $frequency\_map[result] \gets frequency\_map[result] + 1$
%\EndFor
%\State $max\_freq \gets max(frequency\_map.values())$
%\State $consensus\_result \gets argmax(frequency\_map, max\_freq)$
%\For{each $\omega \in valid\_queries$}             \Comment{Find query producing consensus result}
    %\If{$execute(\omega, s) = consensus\_result$}
        %\State \Return $\omega$                     \Comment{Return consensus query}
    %\EndIf
%\EndFor
\end{algorithmic}
\end{algorithm}

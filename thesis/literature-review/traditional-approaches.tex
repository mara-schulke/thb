\subsection{Traditional NL2SQL Approaches}

Prior to the wide-spread dominance of machine learning approaches for natural
language processing a variety of traditional, rather discrete approaches have
been explored in the field of NL2SQL. These logical programming
approaches have laid the foundations for transitioning towards the application
of machine learning techniques for NL2SQL.

\subsubsection{Rule-based and Grammar-based Systems}

Foundational research of NL2SQL system mostly focused around applying rule
engines that were tedious to set up and expensive to maintain and transfer
across database systems. These rule engines mostly relied on the systematic
identification of linguistic patterns and were trying to template SQL from
information that was derived from processing the natural language query.
\citep{Rendezvous, Lunar, Ladder}. These approaches mostly tried to formalize
natural language queries into formal grammars which could then be
deterministically mapped into a valid SQL query. \citep{Lunar} These approaches
have strong downsides when it comes to the variety of natural language
constructs they can process, as well as runtime adoption of new / unknown
databases, query constructs etc. A potential upside of this class of NL2SQL
systems is that they can confidently and reproducibly identify questions they
can, and can't answer — thus leading to very reliable and predictable user
interfaces.

\subsubsection{Semantic Parsing using String-Kernels}

A significant milestone in parsing techniques of natural language queries was
reached by \citeauthor*{StringKernels} in \citeyear{StringKernels}. The
introduction of string kernels for semantic parsing represented a novel
achievement, when it comes to fusing logical programming approaches using a
formal grammar like LSNLIS developed by \cite{Lunar} and learning / training
approaches to understand unseen language patterns / unknown natural language
query structures. This allowed for more flexible pattern recognition when
compared to traditional rule-based systems.

The core innovative characteristic of this approach lies in its capability to
understand similarities between natural language expressions based on
subsequence patterns rather than relying on exact matches. This made
\textsc{Krisp}, the research NLIDB system, substantially more robust to
language variations in phrasing and noise (e.g. spelling mistakes) in the
input. As \citeauthor*{StringKernels} demonstrated through experiments on
real-world datasets, this approach compared favorably to existing systems of
the time like \textsc{Chill}, especially in handling noisy inputs — a frequent
challenge rigid rule-based systems faced in real world scenarios
\citep{StringKernels, ILPParsing}.

\subsubsection{Graph Matching Methods}

\citeauthor{GraphMatching} brought together several research threads and
reapplied emerging graph matching research models to natural language
processing, specifically to natural language queries \citep{GraphMatching}.
Graph matching was applied once the natural language query was parsed using a
Combinatory Categorial Grammar (CCG) approach into a semantic graph which
denotes the relationship between semantic entities in it. This graph could then
be matched against the actual graph derived from the database, since they share
topological traits that can be used for matching. This approach allowed to
apply querying systems without having any question-answer pairs or manual
annotations for training the system, which implies easier scalability /
transferability across domains, since the system does not require any
additional tweaks.

Even though this approach was novel and showed improved performance over
existing state-of-the-art approaches, it showed that graph matching quickly
reaches its limitations. This approach depended significantly on the CCG parser's
accuracy, with parsing errors accounting for 10-25\% (depending on the dataset)
of system failures. Furthermore it struggled with both ambiguous language
constructs and potential mismatches between natural language representation of
relationships and database layouts — more complicated database designs, which
may not match the users intuitive understanding resulted in a different
topology and hence could not be matched \citep[p.~387]{GraphMatching}.

\subsubsection{Interactive Systems}

In \citeyear{NALIR} \citeauthor*{NALIR} identified that perfect translation of
natural language into SQL was challenging due to natural language not being
made for query expressions as it heavily relies on contextual information and
clarifying questions in order to disambiguate conversations. These learnings
relate to early prior art from \citeauthor{UnnaturalQueryLanguage} and
\citeauthor{Rendezvous} which also made this observation — ``natural language
is not a natural query language'' \citep{UnnaturalQueryLanguage}. 

NaLIR could accept logically complex English language sentences as input and
translate them into SQL queries, including aggregation, nesting, joins etc. The
key innovative characteristic of NaLIR lies in its interactive communication
mechanism (much like \textsc{Rendezvous}) that could detect potential
misinterpretations and engage users to resolve ambiguities present in their
natural language query without forcing them to entirely rephrase their query.
NaLIR proved that choosing the right interaction model could offset system
limitations — ``In our system, we generate multiple possible interpretations
for a natural language query and translate all of them in natural language for
the user to choose from'' \citep{NALIR}.

\subsubsection{Query Synthesis}

\citeauthor{SQLizer} introduced SQLizer, which synthesizes SQL queries from
natural language. This paper presents a novel approach when it comes to NL2SQL
as it is merging prevalent semantic parsing techniques (outlined above) with a
program synthesis (or query synthesis) approach. SQLizer makes use of a three
stage processing model for natural language models: first generating a sketch
of the query using semantic parsing, then using type-directed synthesis to
complete the sketch and finally using automated repair, if required.

\citeauthor*{SQLizer} show that alternating between repairing and synthesis
yields results that beat state-of-the-art NL2SQL approaches like NaLIR. SQLizer
is fully automated and database-agnostic, requiring no knowledge of the
underlying schema. The authors evaluated SQLizer on 455 queries across three
databases, where it ranked the correct query in the top 5 results for roughly
90\% of the queries, representing a significant improvement over NaLIR
\citep{NALIR}.

Potential shortcomings of this approach include queries which yield empty
results, dealing with language variations as SQLizer is still using semantic
parsing, and domain-specific terminology, all while still requiring users to
select from multiple query options which reduces the overall usability of the
system \citep[p.22-23]{SQLizer}.

\subsubsection{Limitations of Traditional Approaches to NL2SQL}

Many of the outlined approaches faced severe challenges when moving outside of
of research environments. Frequently systems performed comparatively good on
research benchmarks that were often compriised of controlled question types and
limited data variety. Ultimatively no standard benchmarks existed for NL2SQL in
this time, hence comparing multiple NL2SQL systems with each other was not
easily feasible. Nonetheless, several fundamental challenges emerged:

\begin{enumerate}
    \item \textbf{Limited linguistic coverage} — Prevalent rule-based and
        semantic-parsing based systems were only able to process the a small
        subset of the natural language they were programmed for. This severely
        limited their ability to handle different phrasings of the same
        question \citep{StringKernels, UnnaturalQueryLanguage, Lunar, Ladder}.
    \item \textbf{Transferability} — Traditional approaches typically required
        extensive manual configuration or training phases for each database
        they were deployed for, making cross domain usage expensive and
        time-consuming \citep{NLIDBs, Lunar}.
    \item \textbf{Brittleness} — Legacy NL2SQL systems did not handle synonyms,
        paraphrasing, or spelling errors. Manual adaption and handling was
        needed to remediate. \citep{StringKernels, SQLizer}.
    \item \textbf{Poor scalability} — With potentially more complex underlying
        databases, traditional solutions often showed to perform worse.
        \citeauthor*{GraphMatching} found, that with increasing schema
        complexity more compute was required to resolve the natural language
        query, thus harming scalability \citep{GraphMatching}.
\end{enumerate}

These flaws of traditional NL2SQL approaches made it apparent, that a different
class of approaches is needed, which increase transferability and reduce the
brittleness since users are ``unwilling to trade reliable and predictable user
interfaces for intelligent but unreliable ones'' according to
\cite{NLIDBTheory}. Whilst many approaches outlined tractable ways to increase
user satisfaction and accuracy (like \citeauthor*{Rendezvous} did in
\citeyear{Rendezvous} with a conversational approach), NLIDBs were and are not
considered to be a solved problem.

\subsection{Traditional NL2SQL Approaches}

Prior to the wide-spread dominance of machine learning approaches for NLP
a variety of traditional approaches have been explored in the field of NL2SQL.

\subsubsection{Rule-based and Grammar-based Systems}

Foundational research of NL2SQL system mostly focused around applying rule
engines that were tedious to set up, expensive to maintain and transfer
across database systems. These rule engines mostly relied on the systematic
identification of linguistic patterns and were trying to template SQL from
information that was derived from processing the Natural Language Query (NLQ).
\citep{Rendezvous, Lunar, Ladder}. These approaches mostly tried to translate
NLQs into formal grammars which could then be deterministically mapped into a
valid SQL query \citep{Lunar}. These approaches have a limited number of
language patterns they can process and require adoption for new or unknown
databases, query patterns etc. A potential upside of this class of NL2SQL
systems is that they can confidently and reproducibly identify questions they
can, and can't answer — thus leading to reliable and predictable user
interfaces.

\subsubsection{Graph Matching Methods}

\citeauthor{GraphMatching} applied at-the-time emerging graph matching research
models to NLP, specifically to NLQ \citep{GraphMatching}. Graph matching was
applied once the NLQ was parsed using a Combinatory Categorial Grammar (CCG)
into a semantic graph which modeled the relationship between semantic entities.
Subsequently, the graph could be matched against the actual graph derived from
the database. This architecture lead to better transferability across databases
and domains as no fine-tuning per database was needed. Even though graph
matching was an improvement over existing approaches, it quickly reached its
limitations. Graph matching significantly relied on the CCG parser's accuracy,
with parsing errors accounting for 10-25\% of system failures depending on the
dataset. Furthermore it struggled with both ambiguous language constructs and
complex databases schemas which could not be matched
\citep[p.~387]{GraphMatching}.

\subsubsection{Interactive Systems}

In \citeyear{NALIR} \citeauthor*{NALIR} identified that perfect translation of
natural language into SQL was challenging due to natural language not being
made for query expressions as it heavily relies on contextual information and
clarifying questions in order to disambiguate conversations. These learnings
relate to early prior art from \citeauthor{UnnaturalQueryLanguage} and
\citeauthor{Rendezvous} which also made this observation — ``natural language
is not a natural query language'' \citep{UnnaturalQueryLanguage}.
\textsc{NaLIR} could accept logically complex English language sentences as
input and translate them into SQL queries, including aggregation, nesting,
joins etc. The innovation of \textsc{NaLIR} lies in its interactive
communication that could detect potential misinterpretations and engage users
to resolve ambiguities present in their NLQ without forcing
them to entirely rephrase their query. NaLIR proved that choosing the right
interaction model could offset system limitations — ``In our system, we
generate multiple possible interpretations for a NLQ and
translate all of them in  language for the user to choose from''
\citep{NALIR}.

\subsubsection{Query Synthesis}

\citeauthor{SQLizer} introduced SQLizer, which synthesizes SQL queries from
natural language. This paper presents a query synthesis approach. SQLizer makes
use of a three stage processing model: first generating a sketch of the query
using semantic parsing, then using type-directed synthesis to complete the
sketch and finally using automated repair if required. \citeauthor*{SQLizer}
showed that alternating between repairing and synthesis yielded results that
outperformed prevalent NL2SQL approaches like \textsc{NaLIR}. \textsc{SQLizer}
is fully automated and database-agnostic, requiring no knowledge of the
underlying schema. The authors evaluated \textsc{SQLizer} on 455 queries across
three databases, where it ranked the correct query in the top 5 results for
roughly 90\% of the queries, representing a significant improvement over
\textsc{NaLIR} \citep{NALIR}. This approach had shortcomings like yielding
empty results, constrained language variation support and limited
transferability \citep[p.22-23]{SQLizer}.

\subsubsection{Limitations of Traditional Approaches to NL2SQL}

Many of the outlined approaches faced severe challenges when moving outside of
of research environments. Frequently systems performed comparatively good on
research benchmarks that were often compriised of controlled question types and
limited data variety. Ultimatively no standard benchmarks existed for NL2SQL in
this time, hence comparing multiple NL2SQL systems with each other was not
easily feasible. Nonetheless, several fundamental challenges emerged:

\begin{enumerate}
    \item \textbf{Limited language coverage} — Traditional NL2SQL systems were
        only able to process the a small subset of natural language constructs
        they were programmed for \citep{StringKernels, UnnaturalQueryLanguage,
        Lunar, Ladder}.
    \item \textbf{Transferability} — Traditional approaches typically required
        manual configuration or training phases for each database they were
        deployed for, making cross domain usage expensive and time-consuming
        \citep{NLIDBs, Lunar}.
    \item \textbf{Brittleness} — Legacy systems did not handle synonyms,
        paraphrasing, or spelling errors. Manual adaption and handling was
        needed to remediate. \citep{StringKernels, SQLizer}.
    \item \textbf{Poor scalability} — With potentially more complex underlying
        databases, traditional solutions often showed to perform worse.
        \citeauthor*{GraphMatching} found, that with increasing schema
        complexity more compute was required to resolve the natural language
        query, thus harming scalability \citep{GraphMatching}.
\end{enumerate}

These flaws of traditional NL2SQL approaches made it apparent, that a different
class of approaches is needed, which increase transferability and reduce the
brittleness since users are ``unwilling to trade reliable and predictable user
interfaces for intelligent but unreliable ones'' according to
\cite{NLIDBTheory}. Whilst many approaches outlined tractable ways to increase
user satisfaction and accuracy (e.g. through conversational approaches like
\cite{Rendezvoue}), NLIDBs were and are not considered to be a solved problem.

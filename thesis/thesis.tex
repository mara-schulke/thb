\documentclass{article}

\usepackage[a4paper]{geometry}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{float}
\usepackage{hyperref}
\usepackage{titlesec}
\usepackage[natbibapa]{apacite}

\graphicspath{{./images/}}

\pagestyle{fancyplain}
\fancyhf{}
\lhead{\fancyplain{}{Mara Schulke} }
\rhead{\fancyplain{}{\today}}
\cfoot{\fancyplain{}{\thepage}}

\newcommand{\figuresource}[1]{
	\begin{center}Quelle: {#1}\end{center}
}

\titleformat{\chapter}{\normalfont\Large\bfseries}{\thechapter.}{20pt}{\Large}
\titleformat{\section}{\normalfont\large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalfont\normalsize\bfseries}{\thesubsection}{1em}{}
\titleformat{\subsubsection}{\normalfont\small\bfseries}{\thesubsubsection}{1em}{}

\begin{document}

\begin{titlepage}
    \begin{center}
        \begin{Large}
            Brandenburg University of Applied Sciences \\[1em]
        \end{Large}
        IT Security \\
        Computerscience \\
        Prof. Dr. Oleg Lobachev \\
        MSc. Florian Eich
    \end{center}

    \vfill

    \begin{center}
        \Large{Reliable Natural Language Interfaces using LLMs, Self-Correction and Incremental Schema Analysis}\\[0.5em]
        \large{Bachelor Thesis}\\[1em]
        
        \begin{normalsize}
            Summer semester 2025\\[0.25em]
            \today
        \end{normalsize}
    \end{center}

    \vfill

    \begin{center}
        Mara Schulke – Matr-Nr. 20215853
    \end{center}
\end{titlepage}

\begin{abstract}
This thesis explores the integration of large language models (LLMs) into PostgreSQL database systems in order
to make the database accessible via natural language instead of the postgres SQL dialect. The research focuses
on implementation strategies, performance optimization, and practical applications of this concept.
\end{abstract}

\tableofcontents

\listoffigures

\section*{List of Abbreviations}
\begin{tabular}{ll}
GPT & Generative Pretrained Transformer \\
SQL & Structured Query Language \\
API & Application Programming Interface \\
LLM & Large Language Model \\
DBMS & Database Management System \\
NL2SQL & Natural Language to SQL \\
\end{tabular}

\newpage

% 1/3 Vorarbeit, Literature Review
% 1/3 Theory, Decomp und System Design
% 1/3 Implementation und Evaluation

% Introduction
\section{Introduction}
\subsection{Problem Statement and Motivation}

Database systems represent a backbone of modern computer science, allowing for rapid advancements
whilst shielding us from the problem categories that come along with managing and querying large amounts
of, usually structured, data efficiently. However, most Database Management Systems (DBMS) have
traditionally required specialized knowledge, usually of the Structured Query Language (SQL), in order
to become useable. Whilst this barrier may be percieved differently across diverse usergroups it
represents a fundamental misalignment between end-user goals (e.g. analysts, researchers, domain experts
etc.) and the underlying DBMS, thus often requiring software engineering efforts in order to reduce this friction.

This barrier is the reason entire classes of software projects exists (for example, admin / support panels),
data analytics tools etc. which therefore introduce significant churn and delay between the implementation
of a database system and reaching the desired end user impact. Often these projects span multiple years, require
costly staffing and yield little to no novel technical value.

Emerging technologies such as Large Language Models (LLMs) have proven themselves as a sensible tool for bridging
fuzzy user provided input into discrete, machine readable formats. Prominent models in this field have demostrated
outstanding capabilities that enable computer scientists to tackle new problem classes, that used to be
challenging / yielded unsatisfying results with logical programming approaches.

This thesis is exploring ways to overcome the above outlined barrier using natural language queries, so that domain experts,
business owners, support staff etc. are able to seamlessly interact with their data, essentially eliminating the
requirement of learning SQL (and its pitfalls). By translating natural language to SQL using Large Language Models
this translation becomes very robust (e.g. against different kinds of phrasing) and enables novel applications
in how businesses, researchers and professionals interact with their data — it represents a fundamental shift 
(ie. moving away from SQL) towards a more inclusive and data driven world. 

\subsection{Objectives of the Thesis}

This thesis aims to address the aforementioned challanges when it comes to database accessibility.
The following objectives are the core research area of this thesis:

\begin{enumerate}
    \item Develop a database extension that can translate natural language queries into semantically
          accurate SQL queries using Large Language Models.
    \item To evaluate the effectiveness and feasibility of different Models aswell as prompt engineering
          techniques in order to improve the performance of the system.
    \item Identify and address issues when it comes to handling amibguous, complex and domain specific user input.
    \item Benchmark the performance of the implementation against common natural language to SQL (NL2SQL) benchmarks.
    \item Idenitfy potential use cases for real world scenarios that could deliver a noticable upsides to users.
    \item Analyze the short commings and limitations of this approach and propose potential solutions to overcome them.
\end{enumerate}  

\subsection{Research Questions}

% \subsubsection{Primary Research Questions}

\subsubsection*{RQ1 — Are natural language database interfaces feasible for real world application?}

The primary research questions when it comes to natural language database interfaces evolve around their
semantic accuracy and reliability, therefore questioning their feasibility for real world usage.
LLMs have notoriously been known for their ability to hallucinate / produce false, but promising outputs.
This behaviour can be especially  dangerous when opting for data driven decisions that rely on false data
due to a mistranslation from natural language to SQL. LLMs could cause hard to understand and debug behaviour,
like false computation of distributions when the intermediate format is not being shown to the user. This
thesis tries to determine whether such hallucinations could be reasonably prevented and whether the associated
performance and hardware requirements are suitable for a real world deployment, outside of research situations.

Specifically the two big underlying questions are:

\begin{enumerate}
    \item Is the semantic accuracy of natural language database interfaces high enough to yield a noticable
          benefit to users?
    \item Is it possible to run such an interface on reasonable, mass available hardware (e.g. excluding high end research GPUs).
\end{enumerate}

\subsubsection*{RQ2 — What approaches are most effective in resolving ambiguity when translating natural language queries into SQL?}

To provide semantically correct results ambiguity in the user-provided natural language queries must be 
adequately addressed. This thesis investigates various approaches to ambiguity management and
resolution. Natural language queries can demonstrate ambiguity even at low levels of complexity —
e.g. there are two different types of "sales" in a database schema, and the user asks to retireve
"all sales".

Such situations present the second major challenge associated with the practical implementation of natural
language database interfaces. The success of this concept will significantly depend on whether suitable 
designs and mitigation techniques can be implemented without creating problems with regards to the 
aforementioned performance and hardware requirements. The research focus lies on both preventative measures
through optimized pre-processing stages and prompt engineering techniques as well as reactive strategies
that post process LLM output, either on the basis of further user input or context inference.

\subsubsection*{RQ3 — Which strategies are increasing semantic accuracy of queries?}

In order to enhance the semantic accuracy a series of improvements may be applied to the pipeline.
Potential optimizations include supplying (parts of) the schema during LLM prompting, implementation of
interactive contextual reasoning through a conversational interface which would allow for user
refinement, the implementation of a robust SQL parsing and validation mechanism and a hybrid approach
partly relying on traditional NLP preprocessing techniques. This research will quantify semantic accuracy
using popular NL2SQL benchmarks and empirically evaluate the impact each approach has on the benchmark
performance. Furthermore this research will take a look at the optimal combination of the aforementioned
solutions in order to develop a system that strikes the right balance between accuracy and performance.

% \subsubsection{Secondary Research Questions}

% \subsubsection*{RQ4 — What use cases are most suitable for natural language database interfaces?}

% \subsubsection*{RQ5 — Where are the limitations of natural language database interfaces?}

% \subsubsection*{RQ6 — How is NL2SQL model performance impacted through model selection, fine tuning and pre/post processing?}

\newpage

\subsection{Structure of the Thesis}

This thesis is following a research and development methodology in order to implement a natural language
interface for databases, in particular postgres is used.

\begin{enumerate}
    \item \textbf{Literature Review} — An analysis of the existing research in the fields of
          natural language interfaces (NLI) for databases, GPU integration for acceleration
          of database operations, and LLM/AI Model integration within database systems.
          This phase establishes the theoretical foundation for this research and identifies current 
          state-of-the-art approaches, their benefits and shortcomings.
     \item \textbf{Decomposition \& Requirements} — Decomposing the problem statement into its
          fundamentals and deriving system requirements for the design phase from it. The goal
          of this section is to arrive at a list of functional and non-functional requirements that
          must be taken into account and fulfilled by the design and implementation phases respectively.
     \item \textbf{System Design} — Design of a system architecture that can utilize GPU acceleration
          for LLM integration from within postgres. The primary goals of the system design phase
          are to arrive at an architecture that yields low latency natural language processing,
          schema-aware SQL query generation, ambiguity detection and resolution whilst maintaining
          a high semantic accuracy.
     \item \textbf{Implementation} — The implementation of a PostgreSQL extension according to the
          above system design that relies on \texttt{rust} and \texttt{pgrx}. This extension will
          provide a GPU accelerated framework for executing LLMs, implement a natural language
          to query generation pipeline that relies on the SQL schema and create database functions
          and operators for both query generation and execution.
     \item \textbf{Evaluation and Benchmarking} — An assesment framework and benchmark that introspects
          the implementations performance in multiple dimensions. Namely the most relevant dimensions
          for this thesis are:
          \begin{enumerate}
              \item Semantic Accuracy — Measuring the overall accuracy of results delivered for a given
                    natural language input.
              \item Ambiguity Resolution Capabilities — How well the system performs when confronted with
                    ambiguous natural language input and database schemas.
              \item Performance Metrics — Measuring the latency, throughput and resource utilization 
                    of the implementation.
          \end{enumerate}
      \item \textbf{Discussion} — Analysis and interpretation of the evaluation phase results against
            the research goals of this thesis. Evaluating the performance and accuracy results recorded
            during the benchmarks against the question whether real world deployments of NILs are feasible.
            Furthermore the effectiveness of ambiguity resolution capabilities and semantic accuracy enhancement
            strategies are showing a statistically significant effect.
       \item \textbf{Summary and Outlook} — Summarizes the contributions, addresses limitations
            of this thesis and the implementation, and proposes directions for future research alongside
            possible applications. Primary future research topics include advanced GPU optimization
            techniques (e.g. further quantization), accuracy and performance impact of model fine tuning,
            techniques, scalability of such a system in enterprise scenarios and the evaluation of security
            and privacy considerations (e.g. managing access control).
\end{enumerate}

\newpage

\section{Literature Review}

% https://github.com/HKUSTDial/NL2SQL_Handbook/blob/main/assets/river.svg

In this section a comprehensive literature review is performed to asses the research landscape on NL2SQL
(sometimes also referred to as Text-to-SQL or T2SQL) and NLIDBs. From the time their development accelerated in
the late 1990s and early 2000s \citep{NLIDBs, NLIDBTheory, ILPParsing, ILPParsing2} until now, observing multiple 
larger paradigm shifts happening over time \citep{GRAPPA, STRUG, Seq2SQL, NALIR, SQLizer}. In particular this 
research focuses on the recent advancements when it comes to language models and how they can be harnessed for
effective NL2SQL systems \citep{LLM-Sql, DAIL-SQL, T2SQL-LLM-Bench-2, T2SQL-LLM-Bench-3, SPIDER2, BIRD}.

This literature review is covering the foundational concepts, challenges, key advancements and research gaps
associated with using natural language instead of SQL. It lays the foundation for this thesis and helps to set
the research questions introduced in the previous chapter in context.

% bessere einleitung

\subsection{Foundations of Natural Language Interfaces to Databases}

Earlier papers in the research landscape on Natural Language Database Interfaces (NLIDBs) date over half
a century back, into the early 1970s. Two decades after the first major research systems where developed
in this domain, \citeauthor*{NLIDBs} have published an introduction and an overview over NLIDBs where an overview of
state-of-the-art approaches were provided. \citep{NLIDBs} Their work outlined multiple key issues and challenges
associated with NLIDBs, and compared them against existing / competing solutions like formal query languages,
form-based interfaces and graphical interfaces. These challenges (like unobvious limits, linguistic ambiguities,
semantic inaccuracy, tedious configuration etc.) have shaped this field of research and are still considered relevant
metrics today.

Early NLIDBs primarily relied on traditional natural language processing (NLP) techniques in order to achieve
natural language understanding capabilities. With \textsc{Chill} an inductive logic programming (ILP) approach
was first introduced for NL2SQL systems, marking one of the key events when it comes to machine learning usage.
\citep{ILPParsing} In \citeyear{ILPParsing2} \citeauthor*{ILPParsing2} have extended the approach of ILP
parsing for natural language database queries with multi clause construction, yielding promising results
in the field of NLIDBs. \citep{ILPParsing2}

Building on the systematic overview of \citeauthor*{NLIDBs} and the first machine learning approaches from
\citeauthor*{ILPParsing} aswell as \citeauthor*{ILPParsing2}, \citeauthor{NLIDBTheory} have proposed a novel 
approach for implementing NLIDBs and outperformed at the time state-of-the-art solutions from \cite{ILPParsing} 
\cite{ILPParsing2} — achieving 80\% semantic accuracy. \citep{NLIDBTheory} The novelty of the \textsc{Percise}
system lies in its natural language processing approach, specifically its lexical mapping strategy, allowing 
\textsc{Percise} to identify questions it can, and can't answer (introducing the concept of \textit{semantically 
tractable questions}) which therefore results in a better and interactive end user experience. Their experiements 
also showed that this approach is \textit{transferrable} and \textit{unbiased} — it is possible to feed in new, 
unknown questions into the system and maintain performance characteristics, whereas it was shown that 
\cite{ILPParsing} were suffering from a distribution drift of the questions asked. \citep{NLIDBTheory}

The theoretical foundations and research questions highlighted by the aforementioned works, shaped the research
field and highlighted the following, ongoing research:

\begin{enumerate}
    \item The trade-off characteristics derived from choosing a machine learning vs. traditional NLP approach (e.g. 
          \textsc{Chill} versus \textsc{Percise}). E.g. coverage versus correctness. \citep{ILPParsing, NLIDBTheory}
    \item The linguistic challenges associated with bringing NLIDBs into use (e.g. semantic inaccuracy, linguistic 
          ambiguity, unclear language coverage etc.) \citep{NLIDBs}
    \item The value of systems and approaches which double down on reliability and semantic accuracy rather than giving
          promising but incorrect answers. \citep{NLIDBs, NLIDBTheory}
\end{enumerate}

Fundamentally this highlights the tension and mismatch between the characteristics of natural language, which is 
able to be ambiguous, \textit{semantically untractable} or able to be incomplete in meaning and formal languages
like SQL which always have on deterministic and \textit{semantically tractable} meaning they convey in each statement. 
As Schneiderman and Norman have pointed out according to \citeauthor*{NLIDBTheory}, users are ``unwilling to trade 
reliable and predictable user interfaces for intelligent but unreliable ones'' which induces performance expectations
on NLIDB implementations to be highly certain about the questions it can, and can't answer, whilst maintaing as high
as possible natural language coverage. \citep{NLIDBTheory}

\subsection{Traditional NL2SQL Approaches}

Prior to the wide-spread dominance of machine learning approaches for natural language processing a variety of
traditional, rather discrtete approaches have been explored in the field of NL2SQL / NLIDBs. These logical
programming approaches have laid the foundations for transitioning towards the application of machine learning
techniques for NL2SQL.

\subsubsection{Rule-based and Grammar-based Systems}

Foundational research of NL2SQL system mostly focused around applying rule engines that were tedious to set up and
expensive to maintain / transfer across database systems. These rule engines mostly relied on the systematic 
identification of linguistic patterns / were trying to template SQL from information that was derived from processing the 
natural language query. \citep{Rendezvous, Lunar, Ladder} These approaches mostly tried to formalize natural language 
queries into formal grammers which could then be deterministically mapped into a valid SQL query. \citep{Lunar} These 
approaches have strong downsides when it comes to the variety of natural language constructs they can process, aswell as 
runtime adoption of new / unknown databases, query constructs etc. A potential upside of this class of NL2SQL systems is 
that they can confidently and reproducably identify questions they can, and can't answer — thus leading to very reliable 
and predictable user interfaces.

\subsubsection{Semantic Parsing using String-Kernels}

A significiant milestone in parsing techniques of natural language queries was reached by \citeauthor*{StringKernels} in 
\citeyear{StringKernels}. The introduction of string kernels for semantic parsing represented a novel achievement, when 
it comes to fusing logical programming approaches using a formal grammer like LSNLIS developed by \cite{Lunar} and 
learning / training approaches to understand unseen language patterns / unknown natural language query structures. This 
allowed for more flexible pattern recognition when compared to traditional rule-based systems.

The core innovative characteristic of this approach lies in its capability to understand similarities between natural 
language expressions based on subsequence patterns rather than relying on exact matches. This made \textsc{Krisp}, the 
research NLIDB system developed by \cite{StringKernels} much more robust to language variations in phrasing and noise 
(e.g. spelling mistakes) in the input. As the \citeauthor*{StringKernels} demonstrated through experiments on real-world 
datasets, this approach compared favorably to existing systems of the time like \textsc{Chill}, especially in handling 
noisy inputs — a frequent challenge rigid rule-based systems faced in real world scenarios \citep{StringKernels, 
ILPParsing}.

\subsubsection{Graph Matching Methods}

\cite{GraphMatching} brought together several research threads and reapplied emerging graph matching research models
to natural language processing, specifically to natural language queries. Graph matching was applied once the natural 
language query was parsed using a Combinatory Categorial Grammar (CCG) approach into a semantic graph which denotes the 
relationship between semantic entities in it. This graph could then be matched against the actual graph derived from 
the database, since they share topological traits that can be used for matching \citep{GraphMatching}. This approach 
allowed to apply querying systems without having any question-answer pairs or manual annotations for training the system, 
which implies easier scalability / transferability across domains, since the system does not require any additional 
tweaks.

Even though this approach was novel and showed improved the performance over existing state-of-the-art approaches, it
was showing that graph matching quickly reaches its limitations. This approach relied heavily on the CCG parser's 
accuracy, with parsing errors accounting for 10-25\% (depending on the dataset) of system failures \citep{GraphMatching}. 
Furthermore it struggled with both ambiguous language constructs and potential mismatches between natural language 
representation of relationships and database layouts — more complicated database designs, which may not match the users 
intuitive understanding resulted in a different topology and hence could not be matched \citep[p.~387]{GraphMatching}.

\subsubsection{Interactive Systems}

In \citeyear{NALIR} \citeauthor*{NALIR} identified that perfect translation of natural language into SQL was challenging
due to natural language not being made for query expressions as it heavily relies on contextual information and clarifying
questions in order to disambiguate conversations \citep{NALIR}. These learnings relate to early prior art from 
\citeauthor{UnnaturalQueryLanguage} and \citeauthor{Rendezvous} which also made this observation — ``natural language
is not a natural query language.'' \citep{UnnaturalQueryLanguage}. The solution introduced by NaLIR further emphasized
how important an interactive, conversational usage model is, when offering a natural language interface \citep{NALIR}.

NaLIR could accept logically complex English language sentences as input and translate them into SQL queries with various 
complexities, including aggregation, nesting, and different types of joins etc. The key innovative characteristic of 
NaLIR lies in its interactive communication mechanism (much like \textsc{Rendezvous}) that could detect potential 
misinterpretations and engage users to resolve ambiguities present in their natural language query without forcing them
to entirely rephrase their query \cite{NALIR}. This approach, while showing awareness for its limitations (with regards
to entirely automating / deriving SQL generation from potentially ambiguous or faulty user input) showed that it was 
possible to overcome these limtations through choosing the right interaction model — ``In our system, we generate
multiple possible interpretations for a natural language query and translate all of them in natural language for the
user to choose from'' —, rather than optimizing the generation part of the system \cite{NALIR}.

\subsubsection{Query Synthesis}

\cite{SQLizer} introduced SQLizer, which synthesizes SQL queries from natural language \citep{SQLizer}. This paper
presents a novel approach when it comes to NL2SQL as it is merging prevalent semantic parsing techniques (outlined above)
with an program synthesis (or query synthesis) approach. SQLizer makes use of a three stage processing model for 
natural language models: first generating a sketch of the query using semantic parsing, then using type-directed
synthesis to complete the sketch and finally using automated repair, if required. 

\citeauthor*{SQLizer} show that alternating between repairing and synthesis yields results that beat state-of-the-art
NL2SQL approaches like NaLIR. SQLizer is fully automated and database-agnostic, requiring no knowledge of the underlying
schema. The authors evaluated SQLizer on 455 queries across three databases, where it ranked the correct query in the
top 5 results for roughly 90\% of the queries. This represents a significant improvement over NaLIR \citep{NALIR},
the previous state-of-the-art system \citep{SQLizer}.

Potential short commings of this approch include queries which yield empty results, dealing with language variations
as SQLizer is still using semantic parsing, and domain-specific terminology, all while still requiring users
to select from multiple query options which reduces the overall usability of the system \citep[p.22-23]{SQLizer}.

\subsubsection{Limitations of Traditional Approaches to NL2SQL}

Despite being innovative and achieving state-of-the-art results, many of the above outlined approaches face severe 
challenges when moving outside of an research environment. Many of these systems performed comparatively good on research
benchmarks that were often composed of controlled question types and limited data variety. Ultimatively no standard
benchmark existed for NL2SQL in this era, hence comparing different NL2SQL systems against each other is a problem on 
its own. Despite not having a standard benchmark that all approaches could be unifiably evaluated against, several 
fundamental challenges emerged / remained with these approaches:

\begin{enumerate}
    \item \textbf{Limited linguistic coverage} — Prevalent rule-based and semantic-parsing based systems were only able to 
          process the a small subset of the natural language they were programmed for. This severely limited their 
          ability to handle different phrasings of the same end-user goal \citep{StringKernels, UnnaturalQueryLanguage, 
          Lunar, Ladder}.
    \item \textbf{Transferability} — Traditional approaches typically required extensive manual configuration or at least
          a training phase / adaption for each database they were deployed for, hindering cross domain usage through being 
          expensive and time-consuming to adapt \citep{NLIDBs, Lunar}.
    \item \textbf{Brittleness} — Many of the systems introduced in this subchapter did not handle synonyms, paraphrasing,   
          or spelling errors well. Manual adaption / handling was needed in order to becomes resilient against each class
          of problems \citep{StringKernels, SQLizer}.
    \item \textbf{Poor scalability} — With potentially more complex underlying databases, traditional 
          solutions often showed to perform worse. \citeauthor*{GraphMatching} found, that with increasing schema
          complexity more compute was required to resolve the natural language query to a suitable query candidate
          making them less transferable and scalable than initially anticipated \citep{GraphMatching} — ``Evaluating on
          all domains in Freebase would generate a very large number of queries for which denotations would have to be 
          computed ... Our system loads Freebase using Virtuoso and queries it with SPARQL. Virtuoso is slow in dealing with
          millions of queries indexed on the entire Freebase, and is the only reason we did not work with the complete
          Freebase.'' which indicates underlying system design issues with runtime complexity.
\end{enumerate}

These flaws of traditional NL2SQL approaches made it apparent, that a different class of approaches is needed, which 
increase transferability and reduce the brittleness since users are ``unwilling to trade reliable and predictable user 
interfaces for intelligent but unreliable ones'' according to \cite{NLIDBTheory}. Whilst many approaches outlined tractable 
ways to increase user satisfaction and accuracy (like \citeauthor*{Rendezvous} did in \citeyear{Rendezvous} with a 
conversational approach), NLIDBs were and are not considered to be a solved problem.

\subsection{Neural NL2SQL Approaches}

The previously outlined limitations of traditional approaches to solving NL2SQL / implementing NLIDBs pushed the research
branch around neural network application forward to step in and propose new solutions which address the brittleness, 
transferability and scalability concerns addressed with logical programming approaches. Neural approaches showed to yield
significant improvements in terms of transferability and overall accuracy which led to a paradigm shift in this research
field.

\subsubsection{Early Neural Approaches}

In \citeyear{Seq2SQL} \citeauthor*{Seq2SQL} released Seq2SQL which represents a significant breakthrough and leap in NLIDB 
research. Seq2SQL was an early research system that in the field of neural network application and as one of the first papers
to frame the implementation of NLIDBs / NL2SQL Systems as a reinforement learning problem. The system utilized iterative query 
execution in the reward function to improve its accuracy \citep{Seq2SQL}. In the same paper \citeauthor*{Seq2SQL} introduced 
WikiSQL, a training dataset, which enables large scale (in \citeyear{Seq2SQL}) model training.

SQLNet \citep{SQLNet} addressed primarily the order-sensitivitiy trait of Seq2SQL \citep{Seq2SQL} that was prevalent due to being
a derivative approach from sequence-to-sequence approaches. SQLNet diverges from sequence-to-sequence and joins multiple research 
threads, employing a sketch-based query generation. SQLNet breaks down complex queries into smaller (hence more manageable)
sub-queries which can then be individually sketched and refined, yielding a system that outperformed state-of-the-art by 9\% 
to 13\% \citep{SQLNet}.

\citeauthor*{TypeSQL} have introduced \textsc{TypeSQL}, a variation of the SQLNet-approach, in \citeyear{TypeSQL}.
\textsc{TypeSQL}'s primary difference to SQLNet is the encoding of type information for SQL generation. The approach scanned
for entity references and values in natural language and was able to improve performance by 5.5\% over SOTA-Models like
SQLNet whilst requiring significantly less training time, indicating that type information was a useful information for deriving 
accurate SQL queries from user input \citep{TypeSQL}.

\subsubsection{Intermediate Neural Developments}

Later in \citeyear{SyntaxSQLNet} \citeauthor*{SyntaxSQLNet} released SyntaxSQLNet, a followup research to \textsc{TypeSQL},
which represented a slight change in approach and research focus. In direct comparison SyntaxSQLNet focused primarily around
complex query generation using a syntax tree decoder, allowing for longer and more cohesive query generation \citep{SyntaxSQLNet}.
This advancement over \textsc{TypeSQL} allowed more complex queries to be reliably generated, enabling multiple clauses aswell as
nested queries. SyntaxSQLNet was one of the earlier research efforts which utilized Spider instead of WikiSQL (introduced by 
\cite{Seq2SQL}), a large-scale NL2SQL dataset, incorperating 10.181 hand annotated natural language question and alongside
5.693 unique SQL examples that spread across 138 different domains \citep{Spider}. This research led the transition of
comparatively simple, research-grade, neural systems for NLIDBs towards systems which are feasible in the real world.

Building on the above approaches, \citeauthor*{IRNet} have introduced IRNet, a neural network approach using intermediate
representation as a bridge between natural language and SQL in which semantic queries could be expressed. The intermediate
format SemQL (or semantic query language) was utilized to transform and synthesize queries on the actual database schema more
accurately than Seq2SQL. IRNet followed a three phase approach: schema linking between the natural language query and database
layout, synthesis of SemQL as intermediate representation and deterministic conversion of SemQL to SQL. This approach allowed
IRNet to outperform state-of-the-art approaches on the \textsc{Spider} benchmark by 19.5\%, placing IRNet at an overall accuracy
of 46.7\% \citep{IRNet}.

Following IRNet, graph neural networks (GNN) have been explored as alternative architecture by \cite{GNN}, representing the
database schema as a graph and using message passing to model relationships between tables, columns and natural language input.
This approach demonstrated the capability to improve reasoning and query generation capability. \citeauthor{GNN} showed that when 
evaluating against the \textsc{Spider} benchmark GNN outperforms both SyntaxSQLNet (and therefore \textsc{SQLNet} \&
\textsc{TypeSQL}). Although presenting a signficiant advancement over previous state-of-the-art approaches, GNN falls behind in
performance against IRNet by 6\% \citep{IRNet, GNN}.

\subsubsection{Relation-Aware Transformer Approaches}

The release of RAT-SQL (Relation-Aware Transformer for SQL) \cite{RATSQL} represents the most significant leap in research of
neural NL2SQL approaches. RAT-SQL diverged from earlier research through emphasizing the relationship between natural language
and the database schema elements using relation-aware self-attention representing a novel approach for solving \textit{schema 
linking} \citep{RATSQL}.

RAT-SQL's primary innovations was the ability to infer, understand and utilize the relationship between individual tokens in the 
natural language query and link it to the database schema. Thus allowing for reasoning capabilities on the actual database schema
while generating the query.

This architecture yielded a 57.2\% in exact match accuracy when being evaluated on the \textsc{Spider} benchmark, substantially
outperforming comparative approaches like GNN, IRNet and IRNet V2 by 10.5\%, 9.8\% and 8.7\% respectively. Although overall
accuracy improved across all approaches when being paired with BERT (Bidirectional Encoder Representations from Transformers, a 
popular pre-trained lanugage model from Google) the $\delta$ between the indivudual approaches remained relatively steady, leaving
RAT-SQL outperforming state-of-the-art approaches by 5\% to 12.2\% further demonstrating the capability advancement yielded by this 
system \citep{RATSQL}.

\subsubsection{Comparative Analysis of Neural Approaches}

The evolution from early neural approaches to RAT-SQL emphasized the rapid advancements that happened in the research field of 
neural NL2SQL approaches in different dimensions:

\begin{enumerate}
    \item \textbf{Model Complexity} — Given the research progression from early sequence to sequence translation approaches 
          (\textsc{Seq2SQL}) towards sketch based and type augumented and graph based approaches (\textsc{TypeSQL, SQLNet, GNN})
          and syntax tree decoding emphasized by \textsc{SyntaxSQLNet}, neural approaches continously advanced in the complexity of 
          approaches that is required to beat state-of-the-art approaches in contemprorary benchmarks like \textsc{Spider}. RAT-SQL 
          presents one of the late and most complex advancements in the field of neural NL2SQL approaches with its adapted self 
          attention mechanism \citep{Seq2SQL, TypeSQL, GNN, SyntaxSQLNet, RATSQL}.
    \item \textbf{Transferability} — Each of the approaches introduced above represents a succession in terms of their transferability.
          The field of neural NL2SQL approaches significantly improved the ability for NLIDBs to generalize over the underlying database
          schemas. RAT-SQL showed the strongest cross-domain accuracy (that is benchmarked by the \textsc{Spider} benchmark). With
          standard benchmarks emerging it became easier to verify and quantify which approach had the highest transferability as
          \textsc{Spider} specifically had independent development and test datasets, preventing approaches from over-optimizing on
          training data \citep{Spider, RATSQL}.
    \item \textbf{Robustness} — As research systems advanced in complexity and shifted from raw input to output translation (Seq2SQL)
          their robustness steadily increased. Through more approaches like \textsc{SyntaxSQLNet} which utilized structured decoding,
          \textsc{IRNet} which relied on an intermediate representation and \textsc{RAT-SQL} the challenges around \textit{schema linking}
          outlined by \cite{RATSQL} have increasilingly led to more robust systems that can handle rephrasings, spelling mistakes and
          variations in natural language usage far beyond what traditional NL2SQL approaches could accomplish \cite{SyntaxSQLNet, IRNet, RATSQL}.
    \item \textbf{Query Complexity} — The performance on complex queries involving multiple tables, relying on complex aggregations,
          nested structures and joins dramatically improved over the course of the research that happened in this field. Whilst 
          \textsc{IRNet} reresents one of the first singificant advancements when it comes to the ability of neural approaches to handle
          complex queries, \textsc{RAT-SQL} still showed to outperform the intermediate representation approach introduced by \textsc{IRNet}
          by up to 10.5\% \citep{IRNet, RATSQL}.
    \item \textbf{Schema Understanding} — Whilst early approaches like Seq2SQL primarily applied reinforcement learning for end to end
          query generation \citep{Seq2SQL}, later approaches like \textsc{TypeSQL, GNN} and specifically \textsc{RAT-SQL} showed novel and state-of-
          the-art \textit{schema understanding / schema linking} capabilities, yielding the ability to accurately reason about user intent and
          traverse the database schema while generating queries \citep{TypeSQL, GNN, RATSQL}. 
\end{enumerate}

\subsubsection{Limitations of Neural Approaches}

Despite the dramatic \textit{accuracy, transferability} and \textit{robustness} improvements that could be observed with late neural
approaches \citep{IRNet, RATSQL}, neural approaches still suffered from serious shortcommings / unsolved challenges:

\begin{enumerate}
    \item \textbf{Training Data} — Utilizing neural networks these approaches required susbtantially more training data (ie. natural language
          paired with output SQL queries) than traditional systems which required serious efforts of data collection \citep{Spider}.
    \item \textbf{Correctness} — The inherent mismatch between neural networks and formal languages yielded cases where models produced
          invalid SQL code. Approaches like \textsc{SyntaxSQLNet} improved the tried to solve this circumstance by utilizing syntax trees
          during decoding but nonetheless syntactic correctness remained a challenge across future iterations of neural systems. \citep{SyntaxSQLNet}
    \item \textbf{Domain Language} — Despite increased \textit{transferability} characteristics neural approaches still suffered from a
          limited vocabulary and inter-domain understanding of terminology and relation between concepts which made highly domain
          specific natural language queries challenging.
    \item \textbf{Observability} — The black-box nature of neural networks made approaches relying on them, particularly the ones with complex
          architectures, hard do understand / explain in case when neural systems yielded undesirable output. 
\end{enumerate}


The introduction and advancement of early neural NL2SQL approaches led to significant advancements in the research and feasibility of
NLIDBs. The research shift started in this era established the foundations for further and more advanced machine learning approaches
(specifically language model oriented approaches )being researched. Neural approaches showed to significant improvements in performance
when being paired with pre-trained language models \citep{RATSQL} which led to further research on their applicability.

\subsection{Pre-trained Language Models}

The advantages of combining specialized neural networks with general-purpose pre-trained language models
led to a pivotal point in the NL2SQL research field towards focusing increasingly on the application of pre-trained
language models for NLIDBs. Models like BERT or T5 offer noticable performance improvements (especially when it
comes to language understanding) over specialized NL2SQL networks due to training happening on unrestrained amounts
of natural language data, instead of pure NL2SQL datasets which are often fairly limited in size and therfore natural
language use — \textsc{Spider2.0} which is a contemprary NL2SQL benchmark consists of just 632 real-world questions 
\citep{SPIDER2}. Thus PLM-based (or at least augumented) NL2SQL systems can observe dramatic performance improvements
through the language models's ability to understand patterns and identify semantic relationships of natural language
query elements. 

\subsubsection{Early Pre-trained Language Model Adaptations}

The above outlined benefits have led to concrete research efforts focusing on the question whether the sole application
of pre-trained language models could outperform neural state-of-the-art approaches — which often implicitly require
a far more sophisticate architecture when it comes to natural language analysis.

In the time of emerging PLM applicationm \textsc{Grappa} was introduced by \citeauthor*{GRAPPA} in \citeyear{GRAPPA} —
a novel grammar-augmented pre-training approach built on RoBERTa\textsubscript{\tiny{LARGE}} (a derivative model from BERT).
It generates synthetic training data (ie. natural language and sql pairs) using a synchronous context-free grammar (SCFG)
which analyses and identifies patterns in natural language queries that can be used as templates for sythesizing training
data. The specialized pre-training helps \textsc{Grappa} to establish a robust connection between natural-language and
database schema elements, showing significant improvements on existing approaches on multiple contemporary benchmarks like 
\textsc{Spider} and \textsc{WikiSQL} \citep{GRAPPA}.

Several NL2SQL approaches in this era focused on \textit{schema understanding} and \textit{schema linking} — the 
generalizability of PLMs required advanced techniques on ensuring that models both understand the semantic intent
of users when querying and correctly identify database schema elements in natural language queries. Thus improving
semantic accuracy of generated SQL queries. \textsc{StruG} (Structure-Grounded-Pretraining) was introduced in
\citeyear{STRUG} by \citeauthor*{STRUG} and presented a novel pretraining approach that improves model abilities when it comes to
\textit{schema linking}, it separates the problem in three facets: column grounding, value grounding and
column-value mapping. In direct comparison with \textsc{Grappa}, \textsc{StruG} achieves similar performance
while being significantly cheaper to train \citep{STRUG}.

In parallel, \citeauthor*{GAZP} released GAZP (Grounded Adaptation for Zero-shot Executable Semantic Parsing) in
\citeyear{GAZP}. \citeauthor*{GAZP} specifically addressed the challenge of adapting semantic parsers across databases
/ domains which was a apparent problem with neural approaches which had a strong tendency to overfit on benchmark datasets. 
Its novel contribution was the combination of forward semantic parsing with a backward utterance generator which allowed
for data synthesis in unseen environments which could then be used to adapt the semantic parser \citep{GAZP}. This
approach enables a improvement in robustness and accuracy in situations where training and inference environments
differ without requiring manually annotated examples \citep{GAZP}.

\subsubsection{Advanced Pre-trained Language Model Approaches}

Building on earlier foundational research on PLM application for NL2SQL tasks, researchers have developed increasingly complex
systems that leveraged pre-trained language models whilst addressing their limitations when it comes to generating valid SQL.

\citeauthor*{RYANSQL} introduced \textsc{Ryansql} (Recursively Yielding Annotation Network for SQL) in \citeyear{RYANSQL},
which implements a sketch-based approach for decomposing complex SQL generation into multiple smaller problems. \textsc{Ryansql}
transformed nested statements into a set of top-level statements using the Statement Position Code (SPC) technique. This
flattening of structure allowed \textsc{Ryansql} to limit the complexity of the query generation problem whilst maintaining
its ability to answer complex questions by recomposing complex queries from their parts. This approach allowed \textsc{Ryansql}
to achieve 58.2\% accuracy on the \textsc{Spider} benchmark, representing a 3.2\% improvement over contemporary state-of-the-art
approaches at the time \citep{RYANSQL}. The sketch-based approach makes \textsc{Ryansql} a PLM-augumented successor of \textsc{SQLNet}
which was a early neural approach to employ sketch-based query generation \citep{RYANSQL, SQLNet}.

A significant advancement in terms of execution accuracy was reached with the application of T5-Models for NL2SQL tasks. T5
(Text-to-Text Transfer Transformer) Models have proven themselves as well-suited for for query generation — T5-3B for NL2SQL
yielded 71.4\% execution accuracy and thus presented a breakthrough in this domain of research \citep{T2SQL-LLM-Bench-3}.
This established a new baseline for PLM-based approaches and demonstrated that general-purpose language models could not
only compete but outperform specialized architectures by far when properly fine-tuned \citep{T2SQL-LLM-Bench-3}.

Following the adavancements through T5, \citeauthor*{GRAPHIX} introduced GRAPHIX-T5 in \citeyear{GRAPHIX}, which combined
the T5 PLMs with a further graph-aware layers for NL2SQL tasks. This architecture could leverage both pre-trained knowledge
of T5 models aswell as the database schema structure during inference. GRAPHIX-T5 constructs a schema graph where nodes
represent tables and columns and edges represent relationships between them, such as foreign keys or columns association.
This architecture allows the model to deeply understand relationships and the layout of the database schema \citep{GRAPHIX}. 
GRAPHIX-T5 outperformed standard T5 models significantly, with GRAPHIX-T5\textsubscript{\tiny{LARGE}} showing 6.6\% increase
in execution accuracy over T5\textsubscript{\tiny{LARGE}}. When both GRAPHIX and the baseline T5 models were combined with
\textsc{Picard} (a novel constrained decoding mechanism) absolute $\delta$ between them jumped to 7.6\% (81.0\% in absolute
numbers), evaluated on \textsc{Spider-Dev} \citep{GRAPHIX}.

In parallel, \citeauthor*{RESDSQL} proposed \textsc{Resdsql} in \citeyear{RESDSQL}, which proposed to decouple
\textit{schema linking} and \textit{skeleton parsing}. This addressed the typical challenges sequence-to-sequence models
faced when simultaneously trying to link both schema elements and generate the query skeleton (e.g. 
\texttt{SELECT <columns> FROM <table>}). \textsc{Resdsql} further employed a ranking approach to filter schema elements
before passing them to the model for query generation, which reduced noise (when working with large database schemas)
and enabled passing only the most relevant parts. This twofold approach allowed \textsc{Resdsql} to achieve state-of-the-art
performance when being evaluated on \textsc{Spider}, outperforming GRAPHIX-T5\textsubscript{\tiny{3B}}-PICARD by 0.8\% in
execution accuracy. When combined with \textsc{NatSQL} (a contemporary intermediate representation approach introduced
by \cite{NATSQL}) absolute improvement over GRAPHIX-T5\textsubscript{\tiny{3B}}-PICARD jumped to 3.1\% emphasizing the
robustness gain decoupeled architectures have over model-oriented approaches.

These advancement showed rapid improvements over earlier methods — far surpassing neural approaches — through advanced
mechanisms when it comes to schema understanding and query generation. The wide language understanding inherited from
PLM-basemodels further strengthens robustness and shows effectiveness through a large gain on the \textsc{Spider}
benchmark. Collectively these approaches represent a leap in NL2SQL research, emphasizing their usability potential
and real-world feasibility. This era primed the research field for the transition towards large language model adoption.

\subsubsection{Constrained Decoding and Ranking Techniques}

A major challenge in NL2SQL research is making sure that model generated queries are not just semantically accurate
but also syntactically valid queries and thus executable. To address this issue \citeauthor*{PICARD} released \textsc{Picard}
(Parsing Incrementally for Constrained Auto-Regressive Decoding) in \citeyear{PICARD}, a constrained decoding mechanism
for language models which utilizes the SQL grammar and constrained decoding mechanisms to incrementally parse the generate SQL,
rejecting invalid tokens based on the grammar. \textsc{Picard} showed to significantly improve the performance of pre-trained
language models (like T5 or BERT) when it comes to NL2SQL tasks, lifting them from mid-level to state-of-the-art solutions
on the \textsc{Spider} benchmark \citep{PICARD}.

\textsc{Picard} operates as a incremental parser during model output decoding of pre-trained language models and continuously
evaluates the probability of each token. Instead of just passing model outputs to a database for execution \textsc{Picard}
incrementally parses and validates the generated SQL, rejecting tokens if neeeded thus significantly improving the valid
output accuracy (sometimes referred to as VA) of language models. This approach is addressing a significant issue associated
with pre-trained language models — while they outperform in natural language understanding and reasoning, they often lack
SQL grammer knowledge and tend to generate queries that are not executable due to ther unconstrained output space \citep{PICARD}.

The above introduces RESDSQL built ontop of \textsc{Picard}'s foundations and used a ranking-enhanced framework for input
encoding. These two approaches represent a unqiue class of approaches that utilize input and output constraining in order
to increase the performance characteristics of pre-trained language models \citep{RESDSQL}.

\subsubsection{Advantages of PLM Approaches}

PLM approaches to NL2SQL tasks have yielded significant performance improvements for the NL2SQL domain and represent a
leap in NLIDB-research. They primed the research field towards using language models which led to a transition towards
large language models in the following years. Namely PLM approaches brought a series of upsides with them:

\begin{enumerate}
    \item \textbf{Compute Efficiency} — PLMs like \textsc{RESDSQL} achieve high accuracy (up to 84.1\% on \textsc{Spider}
        depending on variants) wilst using far fewer parameters than conteporary LLMs, making them significantly more efficient
        and therefore reduce hardware requirements for their deployment \citep{RESDSQL}.
    \item \textbf{Transferability} — Approaches like \textsc{Grappa} and \textsc{StruG} can incorporate domain-specific understanding
        of natural language, table structures and SQL syntax during pre-training which addressed one of the primary issues with neural
        approaches \citep{GRAPPA, STRUG}.
    \item \textbf{Vocabulary} — PLMs offer a larger vocabulary due to the vast amounts of training data available. This enables them to
        handle a wide variety of natural language patterns which addresses the benchmark-overfitting tendency of neural approaches which
        primarily trained on the development sets of contemporary benchmarks.
\end{enumerate}

\subsubsection{Limitations of PLM Approaches}

Although representing the state-of-the-art at the time, PLMs introduce a class of problems which are associated with their
non-NL2SQL associated nature. There have been an array of approaches to mitigate these shortcommings but nonetheless they
must be considered when using a PLM-based approach to NL2SQL:

\begin{enumerate}

    \item \textbf{Fine-tuning Requirements} — Most PLMs require substantial domain-specific, or at least NL2SQL specific,
          fine-tuning, limiting a straight forward adaptation to new domains or databases. Although being significantly
          more efficient than LLM-based approaches the potential need for initial fine-tuning represent a significant
          computational resource burden. Furthermore when not using synthetic data generation (e.g. \textsc{Grappa})
          annotated datasets of training data are needed to achieve appropiate performance characteristics \citep{GRAPPA}.
    \item \textbf{Wide Input \& Output Space} — Due to the general nature of PLMs their input and output space is often
          far larger than needed 
          NL2SQL tasks. ``Large pre-trained language models for textual data have an unconstrained output space; at each
          decoding step, they can produce any of 10,000s of sub-word tokens'' \citep{PICARD}. This applies to both the
          input and output token space, therefore multiple approaches have been researched which focus on constraining
          these to the subset needed for NL2SQL tasks. Namely GRAPHIX-T5 and \textsc{Picard} have proposed potential
          (and promising) solutions to this issue \citep{GRAPHIX, PICARD}.
    \item \textbf{Limited Schema Awareness} — Due to being general purpose, and non-NL2SQL optimized, PLMs tend to
          incorporate limited amounts of schema awareness when being applied out of the box for NL2SQL tasks. Multiple
          research efforts focused on improving this situation, most notably \textsc{Resdsql} and GRAPHIX-T5 tried to
          improve the schema linking \& awareness of PLMs \citep{RESDSQL, GRAPHIX}, nonetheless the non-specialized nature
          of PLMs prevents NL2SQL being part of the fundamental model architecture.
\end{enumerate}

These characteristics positioned PLMs as powerful but comparatively resource-intensive solutions for NL2SQL (especially
in direct comparison with neural approaches), ultimately yielding the research domain to transition toward exploring
Large Language Model approaches that promise even greater flexibility in adaptation and potentially superior handling
of complex queries through advanced in-context learning approaches.

\subsubsection{Comparison with Large Language Models}

The research on applying pre-trained language models for NL2SQL tasks primed the field for the transition towards LLM usage. While
PLMs like T5 and BERT range from millions to a few billion parameters, prevalent LLMs such as GPT-3 and GPT-4 operate at
significantly larger scales, ranging from a few billions to hundred of billions parameters. The scale of LLMs enables in-context
learning techniques that enable significantly easier and cheaper transferability of NL2SQL systems across domains \citep{DAIL-SQL}.
The $\delta$ of deployment, inference and training requirements of these two approaches are significant due to the size difference
in models, which transfer to hardware requirements and therefore cost. While PLMs can require extensive fine-tuning on domain-specific
data which may aswell be resource intensive \citep{GRAPHIX, RESDSQL, GRAPPA, STRUG}, LLMs transfer the cost to the inference environment,
where model modificants are less impactful, due to the extensive pre-training that took place. Approaches like \textsc{DinSQL} show
that with the application of LLMs the engineering challenges around model instruction gained relevance while model training became
less of a central problem to solve \citep{DINSQL}.

\subsection{Large Language Models}

The emergence of LLMs such as GPT-3, GPT-4, and Claude fundamentally transformed the landscape of NL2SQL research. Early experiments 
with LLMs for NL2SQL tasks showed state-of-the-art capabilities in comparsion with contemporary PLM approaches \citep{DAIL-SQL}.
\cite{T2SQL-LLM-Bench-3} demonstrated that \textsc{Codex} (a contemporary model based on GPT-3), without any fine-tuning efforts,
could achieve competitive performance on \textsc{Spider}, outperforming many state-of-the-art approaches that required extensive
training. This breakthrough challenged the contemporary assumption that further specialization of model architectures would yield
increases in NL2SQL performance (e.g. \textsc{Graphix-T5}) \citep{GRAPHIX}.

\subsubsection{In-Context Learning}

In-Context Learning (ICL) is a foundational approach for leveraging the ability of LLMs to utilize larger context windows for
inference than traditional PLMs. Typical context windows of state-of-the-art LLMs can reach up to hundred thousands of tokens.
This characteristic of LLMs enabled researchers to utilize this context window to provide examples of accurate NL2SQL translation
instead of applying parameter updates. This paradigm shift has made developing NL2SQL systems significantly more accessible.

The fundamental principle of few-shot learning for NL2SQL involves providing the LLM with a small number of example pairs
of natural language and their corresponding SQL representation. These examples can benefit the model's understanding of
mapping between natural language and SQL syntax. This essentially builds on top of prior research like \textsc{Grappa}
and \textsc{StruG}, but applying these examples at inference time, rather than training time. Although this increases
the inference cost of such a system, the upsides lie primarily in the flexibility of such an approach — database content
/ prior usage of the system can be dynamically utilized, rather than requiring retraining.

Example selection strategies showed to have a significant impact on ICL performance. \cite{DAIL-SQL} evaluated
various example selection methods like \textit{Random}, \textit{Question Similarity Selection (QTS)}, 
\textit{Masked Question Similarity Selection (MQS)}, and \textit{Query Similarity Selection (QRS)}. \citeauthor*{DAIL-SQL}
propose a novel strategy to select, organize and present ICL examples to LLMs. DAIL-SQL utilizes both question and
query similarity, masking domain-specific words and prioritizing examples that exceed a similarity threshold of $\tau$
\citep[p.~5]{DAIL-SQL}. DAIL-SQL encodes examples as question-SQL-pairs without the respective schema to improve
token efficiency. Using a Code Representation Prompt (CR) for question and schema encoding yielded DAIL-SQL to achieve
state-of-the-art 86.6\% execution accuracy on \textsc{Spider}.

The comparison between zero-shot and few-shot performance reveals the significant impact of supplying in-context examples
to models. While LLMs demonstrate impressive zero-shot capabilities, with models like GPT-4 achieving 72.3\% execution
accuracy on \textsc{Spider} without any examples \citep[Table 1, p.~8]{DAIL-SQL}, few-shot learning shows to substantially
improve execution accuracy. \cite{DAIL-SQL} shows that even one-shot learning boosts GPT-4's execution accuracy to 80.2\%,
representing a 7.9\% increase, while five-shot learning reaches 82.4\% \citep[Table 2, p.~8]{DAIL-SQL}. This improvement
in execution accuracy is particularly noticable for complex queries which involve multiple joins or nested subqueries,
where zero-shot approaches often fail generate semantically accurate SQL queries \citep{DAIL-SQL}. Notable is the
leap in exact match ratio measured by the \textsc{Spider} benchmark — jumping from 22.1\% for GPT-4 using zero-shot to
71.9\% with five-shot. The results presented by \cite{DAIL-SQL} show signficant correlation between $k$ and the execution
accuracy of $k$-shot approaches.

The effectiveness of ICL approaches has established them as the standard technique applied in LLM-based NL2SQL systems.
They provide a robust foundation which can be extended with advanced techniques such as problem-decomposition, self-correction
and chain-of-thoughts. ICL alone is still subject to frequent limitations observed with NL2SQL systems like ambiguoity handling,
schema linking and dealing with complex queries. This motivated further research of LLM-based NL2SQL systems.

\subsection{Research Gaps}

\subsubsection{Deployment Gaps}

\newpage

\section{Theoretical Foundations}

\subsection{Problem Decomposition}

\subsection{Requirements}

% Conceptual Design
\subsection{System Design}

\subsubsection{Architecture Design}

\subsection{Technical Implementation Strategies}

\newpage

% Implementation
\section{Implementation}

\subsection{Development Environment and Tools}

\subsection{Integration of the Model}


\subsection{Development of the PostgreSQL Extension}


\subsection{Optimization}

\newpage

% Evaluation
\section{Evaluation}

% https://github.com/petavue/NL2SQL-Benchmark/blob/main/results/Report/NL2SQL%20Benchmark%20Report.pdf

\subsection{Test Environment and Methodology}

\subsection{Performance Tests}
\subsubsection{Latency}
\subsubsection{Throughput}
\subsubsection{Scalability}

\subsection{Use Cases}
\subsubsection{Natural Language Queries}
\subsubsection{Text Generation Within the Database}
\subsubsection{Semantic Search and Text Classification}

\subsection{Comparison with Alternative Approaches}

\newpage

% Discussion
\section{Discussion}

\subsection{Interpretation of Results}
\subsection{Limitations of the Implementation}
\subsection{Ethical and Data Privacy Considerations}
\subsection{Potential Future Developments}

\newpage

% Summary and Outlook
\section{Summary and Outlook}

\subsection{Summary of Results}
\subsection{Addressing the Research Questions}
\subsection{Outlook for Future Research and Development}

\newpage

\newpage

\appendix
\section*{Appendix}
\subsection*{Installation Guide}
\subsection*{API Documentation}
\subsection*{Code Examples}
\subsection*{Test Data and Results}

\bibliographystyle{apacite}
\bibliography{references}

\end{document}